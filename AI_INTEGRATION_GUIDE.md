# AI Cost Optimization - Integration Guide

This guide shows you how to integrate the AI cost optimization system into your trading application.

## Table of Contents

1. [Prerequisites](#prerequisites)
2. [System Initialization](#system-initialization)
3. [Agent Integration](#agent-integration)
4. [API Integration](#api-integration)
5. [Configuration](#configuration)
6. [Usage Examples](#usage-examples)
7. [Monitoring and Debugging](#monitoring-and-debugging)

---

## Prerequisites

### Required Dependencies

```bash
pip install redis anthropic openai aiohttp pydantic
```

### Environment Variables

```bash
# .env file
DEEPSEEK_API_KEY=your_deepseek_api_key_here
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
```

### Redis Setup

```bash
# Install Redis (macOS)
brew install redis
brew services start redis

# Install Redis (Ubuntu)
sudo apt-get install redis-server
sudo systemctl start redis-server
```

---

## System Initialization

### Step 1: Initialize AI Service

Create a singleton instance of `IntegratedAIService` in your application startup:

```python
# backend/src/main.py or backend/src/services/__init__.py

import redis.asyncio as redis
from src.services.ai_optimization import get_integrated_ai_service

# Global AI service instance
_ai_service = None
_redis_client = None

async def initialize_ai_service():
    """Initialize AI service on application startup"""
    global _ai_service, _redis_client

    # Initialize Redis client
    _redis_client = redis.Redis(
        host=os.getenv("REDIS_HOST", "localhost"),
        port=int(os.getenv("REDIS_PORT", 6379)),
        db=int(os.getenv("REDIS_DB", 0)),
        decode_responses=True
    )

    # Initialize AI service with Redis
    _ai_service = get_integrated_ai_service(redis_client=_redis_client)

    print("‚úÖ AI Cost Optimization System initialized")
    print(f"   - Model: {_ai_service.MODEL_VERSION}")
    print(f"   - Redis: Connected")
    print(f"   - Caching: Enabled")
    print(f"   - Event-Driven: Enabled")

async def shutdown_ai_service():
    """Cleanup on application shutdown"""
    global _redis_client
    if _redis_client:
        await _redis_client.close()
        print("‚úÖ AI service shutdown complete")

def get_ai_service_instance():
    """Get the global AI service instance"""
    if _ai_service is None:
        raise RuntimeError("AI service not initialized. Call initialize_ai_service() first.")
    return _ai_service
```

### Step 2: Update FastAPI Lifespan

```python
# backend/src/main.py

from contextlib import asynccontextmanager
from fastapi import FastAPI

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await initialize_ai_service()
    yield
    # Shutdown
    await shutdown_ai_service()

app = FastAPI(lifespan=lifespan)
```

---

## Agent Integration

### Market Regime Agent

```python
# backend/src/api/bot.py or wherever you initialize agents

from src.agents.market_regime.agent import MarketRegimeAgent
from src.services import get_ai_service_instance

# Initialize with AI enabled
ai_service = get_ai_service_instance()

market_regime_agent = MarketRegimeAgent(
    config={
        "enable_ai": True,  # Enable AI enhancement
        "atr_period": 14,
        "adx_period": 14,
        "volatility_threshold": 0.02,
    },
    ai_service=ai_service  # Pass AI service
)

# Use the agent
market_regime = await market_regime_agent.analyze_market_realtime({
    "symbol": "BTC/USDT",
    "exchange": exchange_instance,
    "timeframe": "1h"
})

print(f"Regime: {market_regime.regime_type.value}")
print(f"Confidence: {market_regime.confidence:.2%}")
print(f"AI Enhanced: {market_regime.ai_enhanced}")
```

### Signal Validator Agent

```python
from src.agents.signal_validator.agent import SignalValidatorAgent

signal_validator = SignalValidatorAgent(
    config={
        "enable_ai": True,
        "min_passed_rules": 8,
        "critical_rules": ["price_sanity", "market_hours"],
    },
    ai_service=ai_service
)

# Validate a trading signal
validation = await signal_validator.validate_signal({
    "signal_id": "SIG_001",
    "symbol": "ETH/USDT",
    "action": "BUY",
    "confidence": 0.75,
    "current_price": 2500.0,
    "market_regime": market_regime,
    "exchange": exchange_instance
})

print(f"Validation Result: {validation.validation_result.value}")
print(f"Confidence: {validation.confidence_score:.2%}")
print(f"Failed Rules: {validation.failed_rules}")
```

### Anomaly Detector Agent

```python
from src.agents.anomaly_detector.agent import AnomalyDetectorAgent

anomaly_detector = AnomalyDetectorAgent(
    config={
        "enable_ai": True,
        "check_interval_seconds": 60,
        "anomaly_thresholds": {
            "latency_ms": 5000,
            "error_rate_percent": 5.0,
            "loss_streak": 5,
        }
    },
    ai_service=ai_service
)

# Detect anomalies
anomalies = await anomaly_detector.detect_anomalies({
    "user_id": 1,
    "bot_id": 123,
    "timeframe_minutes": 60
})

for anomaly in anomalies:
    print(f"Anomaly: {anomaly.anomaly_type.value}")
    print(f"Severity: {anomaly.severity.value}")
    print(f"AI Enhanced: {anomaly.ai_enhanced}")
    print(f"Recommended Action: {anomaly.recommended_action}")
```

### Portfolio Optimizer Agent

```python
from src.agents.portfolio_optimizer.agent import PortfolioOptimizerAgent

portfolio_optimizer = PortfolioOptimizerAgent(
    config={
        "enable_ai": True,
        "rebalance_threshold": 0.1,
        "max_position_size": 0.3,
        "risk_levels": {
            "conservative": {"max_drawdown": 0.05, "target_sharpe": 1.0},
            "moderate": {"max_drawdown": 0.10, "target_sharpe": 1.5},
            "aggressive": {"max_drawdown": 0.15, "target_sharpe": 2.0}
        }
    },
    ai_service=ai_service
)

# Optimize portfolio
optimization = await portfolio_optimizer.optimize_portfolio({
    "user_id": 1,
    "risk_level": "moderate",
    "include_ai_insights": True  # Enable AI insights
})

print(f"Portfolio Sharpe: {optimization.portfolio_sharpe:.2f}")
print(f"\nAI Insights:")
for insight in optimization.ai_insights:
    print(f"  - {insight}")

print(f"\nAI Warnings:")
for warning in optimization.ai_warnings:
    print(f"  ‚ö†Ô∏è  {warning}")

print(f"\nAI Recommendations:")
for rec in optimization.ai_recommendations:
    print(f"  üí° {rec}")
```

---

## API Integration

### Step 1: Register AI Cost Router

```python
# backend/src/main.py

from src.api.ai_cost import router as ai_cost_router

app = FastAPI(lifespan=lifespan)

# Register AI cost optimization endpoints
app.include_router(ai_cost_router)

# Other routers
app.include_router(bot_router)
app.include_router(strategy_router)
# ...
```

### Step 2: Update API Dependencies

```python
# backend/src/api/ai_cost.py

import redis.asyncio as redis
from src.services import get_ai_service_instance

async def get_ai_service() -> IntegratedAIService:
    """AI ÏÑúÎπÑÏä§ ÏùòÏ°¥ÏÑ±"""
    return get_ai_service_instance()

async def get_event_opt() -> EventDrivenOptimizer:
    """Ïù¥Î≤§Ìä∏ ÏµúÏ†ÅÌôîÍ∏∞ ÏùòÏ°¥ÏÑ±"""
    ai_service = get_ai_service_instance()
    return ai_service.event_optimizer
```

### Step 3: Test API Endpoints

```bash
# Get cost statistics
curl -X GET "http://localhost:8000/ai-cost/stats"

# Get daily cost
curl -X GET "http://localhost:8000/ai-cost/daily"

# Check budget alert
curl -X GET "http://localhost:8000/ai-cost/budget-alert?daily_budget=5.0&monthly_budget=150.0"

# Get agent breakdown
curl -X GET "http://localhost:8000/ai-cost/agent-breakdown"

# Update sampling strategy
curl -X POST "http://localhost:8000/ai-cost/sampling-strategy" \
  -H "Content-Type: application/json" \
  -d '{
    "agent_type": "market_regime",
    "strategy": "PERIODIC",
    "interval_seconds": 300
  }'

# Update event thresholds
curl -X POST "http://localhost:8000/ai-cost/event-thresholds" \
  -H "Content-Type: application/json" \
  -d '{
    "price_change_pct": 1.5,
    "min_ai_interval": 45,
    "batch_size": 8
  }'
```

---

## Configuration

### Agent Configuration

Each agent can be configured independently:

```python
# config/agents.yaml or config/ai_optimization.yaml

agents:
  market_regime:
    enable_ai: true
    sampling_strategy: "PERIODIC"
    sampling_config:
      interval_seconds: 300  # AI call every 5 minutes

  signal_validator:
    enable_ai: true
    sampling_strategy: "CHANGE_BASED"
    sampling_config:
      threshold: 0.15  # AI call if 15% change in market conditions

  anomaly_detector:
    enable_ai: true
    sampling_strategy: "THRESHOLD"
    sampling_config:
      threshold: 0.7  # AI call if anomaly score > 0.7

  portfolio_optimizer:
    enable_ai: true
    sampling_strategy: "PERIODIC"
    sampling_config:
      interval_seconds: 3600  # AI call every 1 hour
```

### Event-Driven Configuration

```python
# Configure event thresholds
event_optimizer = get_event_optimizer()

event_optimizer.update_thresholds({
    "price_change_pct": 2.0,        # Trigger AI on 2%+ price change
    "volume_spike_multiplier": 3.0,  # Trigger on 3x volume spike
    "volatility_threshold": 1.5,     # Trigger on 1.5%+ volatility
    "min_ai_interval": 60,           # Min 60s between AI calls
    "batch_size": 10,                # Batch 10 LOW priority events
    "batch_timeout": 300             # Process batch after 5min
})
```

### Cost Tracking Configuration

```python
# Set budget alerts
ai_service = get_ai_service_instance()

alert = await ai_service.check_budget_alert(
    daily_budget=10.0,    # $10/day budget
    monthly_budget=300.0  # $300/month budget
)

if alert["daily_usage_percent"] > 80:
    print("‚ö†Ô∏è  Daily budget 80% used!")
    # Implement throttling or notifications
```

---

## Usage Examples

### Example 1: Event-Driven Market Analysis

```python
from src.services.ai_optimization import MarketEvent, EventPriority, EventType

# Create market event
event = MarketEvent(
    symbol="BTC/USDT",
    event_type=EventType.PRICE_CHANGE,
    priority=EventPriority.MEDIUM,
    data={
        "current_price": 45000.0,
        "previous_price": 44000.0,
        "change_percent": 2.27,
        "volume_24h": 1500000000
    }
)

# AI service decides whether to call AI based on event
ai_service = get_ai_service_instance()

result = await ai_service.call_ai_with_event(
    event=event,
    agent_type="market_regime",
    prompt="Analyze current BTC market regime",
    context={"price": 45000.0, "volume": 1500000000},
    system_prompt="You are a crypto market analyst...",
    response_type="market_analysis"
)

# Result includes AI analysis OR cached response
print(f"Called AI: {result['metadata']['ai_called']}")
print(f"Cache Hit: {result['metadata']['cache_hit']}")
print(f"Cost: ${result['metadata']['cost_usd']:.4f}")
```

### Example 2: Batch Processing

```python
# LOW priority events are batched automatically
for i in range(15):
    event = MarketEvent(
        symbol="ETH/USDT",
        event_type=EventType.PRICE_UPDATE,
        priority=EventPriority.LOW,  # Will be batched
        data={"price": 2500.0 + i}
    )

    # This won't call AI immediately
    await ai_service.call_ai_with_event(
        event=event,
        agent_type="portfolio_optimizer",
        prompt=f"Update portfolio with price {event.data['price']}"
    )

# After batch_size (10) or batch_timeout (5min), AI is called ONCE
# Processing 15 events with only 2 AI calls (savings: 87%)
```

### Example 3: Adaptive Sampling

```python
# Configure adaptive sampling for market_regime agent
ai_service.configure_sampling_strategy(
    agent_type="market_regime",
    strategy=SamplingStrategy.ADAPTIVE,
    config={}
)

# Adaptive sampling learns from volatility
# - High volatility ‚Üí more frequent AI calls
# - Low volatility ‚Üí less frequent AI calls
# - Automatically adjusts interval based on market conditions

for _ in range(100):
    market_regime = await market_regime_agent.analyze_market_realtime({
        "symbol": "BTC/USDT",
        "exchange": exchange
    })

    await asyncio.sleep(60)  # Check every minute

# Check adaptive sampling stats
stats = await ai_service.get_cost_stats()
print(f"Adaptive calls made: {stats['sampling']['adaptive_calls']}")
print(f"Calls saved: {stats['sampling']['calls_saved']}")
```

### Example 4: Real-time Cost Monitoring

```python
import asyncio

async def monitor_costs():
    """Real-time cost monitoring loop"""
    ai_service = get_ai_service_instance()

    while True:
        # Get current stats
        stats = await ai_service.get_cost_stats()

        # Check budget
        alert = await ai_service.check_budget_alert(
            daily_budget=10.0,
            monthly_budget=300.0
        )

        # Log to console
        print(f"\n{'='*50}")
        print(f"AI Cost Monitor - {datetime.now().strftime('%H:%M:%S')}")
        print(f"{'='*50}")
        print(f"Total Calls: {stats['overall']['total_calls']}")
        print(f"Total Cost: ${stats['overall']['total_cost_usd']:.4f}")
        print(f"Avg Cost/Call: ${stats['overall']['avg_cost_per_call_usd']:.4f}")
        print(f"Cache Hit Rate: {stats['response_cache']['hit_rate']:.1%}")
        print(f"Daily Budget: {alert['daily_usage_percent']:.1%} used")

        if alert['alerts']:
            print(f"\n‚ö†Ô∏è  ALERTS:")
            for alert_msg in alert['alerts']:
                print(f"  - {alert_msg}")

        await asyncio.sleep(300)  # Update every 5 minutes

# Run in background
asyncio.create_task(monitor_costs())
```

---

## Monitoring and Debugging

### Enable Debug Logging

```python
# backend/src/main.py

import logging

# Enable AI optimization debug logging
logging.getLogger("src.services.ai_optimization").setLevel(logging.DEBUG)
logging.getLogger("src.agents").setLevel(logging.DEBUG)

# Log to file
file_handler = logging.FileHandler("ai_optimization.log")
file_handler.setLevel(logging.DEBUG)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)

logging.getLogger("src.services.ai_optimization").addHandler(file_handler)
```

### Check Redis Cache

```bash
# Connect to Redis CLI
redis-cli

# Check cached prompts
KEYS ai:prompt:*

# Check cached responses
KEYS ai:response:*

# Check cost tracking
KEYS ai:cost:*

# View specific cache entry
GET ai:response:market_regime:BTC/USDT:analyze_regime

# Check TTL
TTL ai:prompt:market_analysis_system_v1

# Clear all AI caches (if needed)
FLUSHDB
```

### Test Cost Optimization

```python
# Test script to verify cost optimization

import asyncio
from src.services import get_ai_service_instance, initialize_ai_service

async def test_cost_optimization():
    await initialize_ai_service()
    ai_service = get_ai_service_instance()

    print("Testing AI Cost Optimization...")

    # Test 1: Prompt caching
    print("\n1. Testing prompt caching...")
    result1 = await ai_service.call_ai(
        agent_type="test",
        prompt="Analyze BTC",
        system_prompt="You are a test analyst",
        response_type="test"
    )
    cost1 = result1["metadata"]["cost_usd"]

    result2 = await ai_service.call_ai(
        agent_type="test",
        prompt="Analyze ETH",
        system_prompt="You are a test analyst",  # Same system prompt ‚Üí cached
        response_type="test"
    )
    cost2 = result2["metadata"]["cost_usd"]

    print(f"  First call: ${cost1:.4f}")
    print(f"  Second call: ${cost2:.4f} (90% discount on cached tokens)")
    print(f"  Savings: {((cost1 - cost2) / cost1 * 100):.1f}%")

    # Test 2: Response caching
    print("\n2. Testing response caching...")
    result3 = await ai_service.call_ai(
        agent_type="test",
        prompt="What is 2+2?",
        context={"test": "same"},
        response_type="test"
    )
    cost3 = result3["metadata"]["cost_usd"]

    result4 = await ai_service.call_ai(
        agent_type="test",
        prompt="What is 2+2?",  # Exact same prompt ‚Üí cached response
        context={"test": "same"},
        response_type="test"
    )
    cost4 = result4["metadata"]["cost_usd"]

    print(f"  First call: ${cost3:.4f}")
    print(f"  Second call: ${cost4:.4f} (response cached)")
    print(f"  Savings: {((cost3 - cost4) / cost3 * 100):.1f}%")

    # Test 3: Event filtering
    print("\n3. Testing event filtering...")
    from src.services.ai_optimization import MarketEvent, EventPriority, EventType

    filtered_count = 0
    ai_called_count = 0

    for i in range(20):
        event = MarketEvent(
            symbol="BTC/USDT",
            event_type=EventType.PRICE_UPDATE,
            priority=EventPriority.LOW,
            data={"price": 45000.0 + i * 10}
        )

        result = await ai_service.call_ai_with_event(
            event=event,
            agent_type="test",
            prompt="Quick check",
            response_type="test"
        )

        if result["metadata"].get("ai_called"):
            ai_called_count += 1
        else:
            filtered_count += 1

    print(f"  Total events: 20")
    print(f"  AI calls: {ai_called_count}")
    print(f"  Filtered: {filtered_count}")
    print(f"  Reduction: {(filtered_count / 20 * 100):.1f}%")

    # Final stats
    print("\n4. Overall statistics:")
    stats = await ai_service.get_cost_stats()
    print(f"  Total calls: {stats['overall']['total_calls']}")
    print(f"  Total cost: ${stats['overall']['total_cost_usd']:.4f}")
    print(f"  Cache hit rate: {stats['response_cache']['hit_rate']:.1%}")
    print(f"  Estimated savings: ${stats['overall']['estimated_savings_usd']:.4f}")

if __name__ == "__main__":
    asyncio.run(test_cost_optimization())
```

---

## Performance Benchmarks

### Expected Results (based on 10,000 operations/day)

| Optimization Layer | API Calls Saved | Cost Reduction | Cumulative Savings |
|-------------------|-----------------|----------------|-------------------|
| Baseline (no optimization) | 0 | $0 | $0 |
| + Prompt Caching | 0 | $4.80/day | 84% |
| + Response Caching | 3,000 | $8.10/day | 90% |
| + Smart Sampling | 4,000 | $10.80/day | 95% |
| + Event Filtering | 6,000 | $13.50/day | 97% |
| + Batch Processing | 7,000 | $15.30/day | 98% |

**Final Result**: $570/month ‚Üí $68/month = **88% cost reduction**

---

## Troubleshooting

### Issue: AI calls not being cached

**Solution**: Check Redis connection and TTL settings

```python
# Test Redis connection
import redis.asyncio as redis

async def test_redis():
    client = redis.Redis(host="localhost", port=6379, decode_responses=True)
    await client.set("test", "value")
    result = await client.get("test")
    print(f"Redis test: {result}")  # Should print "value"

asyncio.run(test_redis())
```

### Issue: High API costs despite optimization

**Solution**: Check sampling strategy and event thresholds

```bash
# Get event stats
curl http://localhost:8000/ai-cost/event-stats

# Check if too many CRITICAL events
# Adjust thresholds if needed
curl -X POST http://localhost:8000/ai-cost/event-thresholds \
  -H "Content-Type: application/json" \
  -d '{"price_change_pct": 3.0, "min_ai_interval": 90}'
```

### Issue: Agents not using AI

**Solution**: Verify `enable_ai=True` in agent config

```python
# Check agent configuration
agent = MarketRegimeAgent(
    config={"enable_ai": True},  # Must be True
    ai_service=get_ai_service_instance()  # Must be provided
)

# Verify AI service is initialized
try:
    ai_service = get_ai_service_instance()
    print("‚úÖ AI service available")
except RuntimeError as e:
    print(f"‚ùå AI service not initialized: {e}")
```

---

## Next Steps

1. **Monitor costs in production** for 1 week to validate savings
2. **Tune sampling strategies** based on actual trading patterns
3. **Adjust event thresholds** to balance cost vs. responsiveness
4. **Build dashboard UI** for real-time cost visualization
5. **Set up budget alerts** with Telegram/Email notifications

---

## Support

For issues or questions:
- Check logs: `tail -f ai_optimization.log`
- Review documentation: `AI_COST_OPTIMIZATION_SYSTEM.md`
- Test endpoints: Use provided curl commands above
